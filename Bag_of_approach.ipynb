{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQF7gtBuN8Wj9wyKX8pP+O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SohanChidrawar/BE_Programming/blob/main/Bag_of_approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fP6pT7L7_1PW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(\"data.csv\")"
      ],
      "metadata": {
        "id": "NQay22j5ApSj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mQ4qWikAsAT",
        "outputId": "aed44af1-d542-4afb-978f-d47ec5b4974e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11914 entries, 0 to 11913\n",
            "Data columns (total 16 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Make               11914 non-null  object \n",
            " 1   Model              11914 non-null  object \n",
            " 2   Year               11914 non-null  int64  \n",
            " 3   Engine Fuel Type   11911 non-null  object \n",
            " 4   Engine HP          11845 non-null  float64\n",
            " 5   Engine Cylinders   11884 non-null  float64\n",
            " 6   Transmission Type  11914 non-null  object \n",
            " 7   Driven_Wheels      11914 non-null  object \n",
            " 8   Number of Doors    11908 non-null  float64\n",
            " 9   Market Category    8172 non-null   object \n",
            " 10  Vehicle Size       11914 non-null  object \n",
            " 11  Vehicle Style      11914 non-null  object \n",
            " 12  highway MPG        11914 non-null  int64  \n",
            " 13  city mpg           11914 non-null  int64  \n",
            " 14  Popularity         11914 non-null  int64  \n",
            " 15  MSRP               11914 non-null  int64  \n",
            "dtypes: float64(3), int64(5), object(8)\n",
            "memory usage: 1.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the text data (if necessary)\n",
        "text_data = data['Market Category'].tolist()"
      ],
      "metadata": {
        "id": "UxYC-5zWAvQh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = data['Market Category'].fillna('').tolist()"
      ],
      "metadata": {
        "id": "Nu4UfuGfA1Gc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bag of Word**\n",
        "\n",
        "The BoW approach provides a numerical representation of text data that can be used as input for machine learning algorithms, allowing them to work with text data effectively."
      ],
      "metadata": {
        "id": "lhFoS97sECfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag-of-Words (BoW)\n",
        "# Count Occurrence\n",
        "count_vectorizer = CountVectorizer()\n",
        "bow_count = count_vectorizer.fit_transform(text_data)"
      ],
      "metadata": {
        "id": "2nypJOjjAx_S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalized Count Occurrence**\n",
        "\n",
        "Normalized count occurrences (TF) represents the relative frequency of terms within individual documents"
      ],
      "metadata": {
        "id": "l_-5bCklFd0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalized Count Occurrence\n",
        "count_vectorizer_normalized = CountVectorizer(binary=True)\n",
        "bow_normalized_count = count_vectorizer_normalized.fit_transform(text_data)"
      ],
      "metadata": {
        "id": "tT-p7WViAz3H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frequency-inverse Document Frequency**\n",
        "\n",
        " IDF represents the discriminative power of terms across the entire document set.\n",
        "\n",
        " 1) Discriminative Power: The discriminative power of a term refers to its ability to differentiate or distinguish between documents in a collection. In the context of natural language processing (NLP) and text analysis, terms with high discriminative power are those that are unique or characteristic to specific documents or classes of documents."
      ],
      "metadata": {
        "id": "bofdgzv8Fr4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf = tfidf_vectorizer.fit_transform(text_data)"
      ],
      "metadata": {
        "id": "-gfUMWBoA4_p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word2Vec**\n",
        "\n",
        "It can be used to capture semantic meanings and relationships between words in a continuous vector space."
      ],
      "metadata": {
        "id": "TSmQvqnEJCdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Word2Vec\n",
        "# Tokenize text data\n",
        "tokenized_data = [text.split() for text in text_data]"
      ],
      "metadata": {
        "id": "Ak4hrEcSA6vz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences=tokenized_data, vector_size=100, window=5, min_count=1, workers=4)"
      ],
      "metadata": {
        "id": "ncF6uqP3A8pb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embeddings\n",
        "word_embeddings = []\n",
        "for text in tokenized_data:\n",
        "    text_embedding = [word2vec_model.wv[word] for word in text if word in word2vec_model.wv]\n",
        "    if text_embedding:\n",
        "        text_embedding_avg = sum(text_embedding) / len(text_embedding)\n",
        "        word_embeddings.append(text_embedding_avg)\n",
        "    else:\n",
        "        word_embeddings.append([0]*100)  # If no word in the text is present in the Word2Vec model, use zero vector\n"
      ],
      "metadata": {
        "id": "_FmS4n33A-eY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the processed output\n",
        "print(\"Bag-of-Words (Count Occurrence):\\n\", bow_count)\n",
        "print(\"\\nBag-of-Words (Normalized Count Occurrence):\\n\", bow_normalized_count)\n",
        "print(\"\\nTF-IDF:\\n\", tfidf)\n",
        "print(\"\\nWord2Vec Embeddings:\\n\", word_embeddings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3xqjio3BALZ",
        "outputId": "ea13baec-7dcc-4424-dfce-81fdc1639ae6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag-of-Words (Count Occurrence):\n",
            "   (0, 3)\t1\n",
            "  (0, 11)\t1\n",
            "  (0, 9)\t1\n",
            "  (0, 7)\t1\n",
            "  (0, 10)\t1\n",
            "  (1, 9)\t1\n",
            "  (1, 10)\t1\n",
            "  (2, 9)\t1\n",
            "  (2, 7)\t1\n",
            "  (2, 10)\t1\n",
            "  (3, 9)\t1\n",
            "  (3, 10)\t1\n",
            "  (4, 9)\t1\n",
            "  (5, 9)\t1\n",
            "  (5, 10)\t1\n",
            "  (6, 9)\t1\n",
            "  (6, 10)\t1\n",
            "  (7, 9)\t1\n",
            "  (7, 7)\t1\n",
            "  (7, 10)\t1\n",
            "  (8, 9)\t1\n",
            "  (9, 9)\t1\n",
            "  (10, 9)\t1\n",
            "  (10, 7)\t1\n",
            "  (10, 10)\t1\n",
            "  :\t:\n",
            "  (11905, 7)\t1\n",
            "  (11905, 10)\t1\n",
            "  (11905, 2)\t1\n",
            "  (11906, 9)\t1\n",
            "  (11906, 6)\t1\n",
            "  (11906, 0)\t1\n",
            "  (11907, 9)\t1\n",
            "  (11907, 6)\t1\n",
            "  (11907, 0)\t1\n",
            "  (11908, 9)\t1\n",
            "  (11908, 6)\t1\n",
            "  (11908, 0)\t1\n",
            "  (11909, 9)\t1\n",
            "  (11909, 6)\t1\n",
            "  (11909, 0)\t1\n",
            "  (11910, 9)\t1\n",
            "  (11910, 6)\t1\n",
            "  (11910, 0)\t1\n",
            "  (11911, 9)\t1\n",
            "  (11911, 6)\t1\n",
            "  (11911, 0)\t1\n",
            "  (11912, 9)\t1\n",
            "  (11912, 6)\t1\n",
            "  (11912, 0)\t1\n",
            "  (11913, 9)\t1\n",
            "\n",
            "Bag-of-Words (Normalized Count Occurrence):\n",
            "   (0, 3)\t1\n",
            "  (0, 11)\t1\n",
            "  (0, 9)\t1\n",
            "  (0, 7)\t1\n",
            "  (0, 10)\t1\n",
            "  (1, 9)\t1\n",
            "  (1, 10)\t1\n",
            "  (2, 9)\t1\n",
            "  (2, 7)\t1\n",
            "  (2, 10)\t1\n",
            "  (3, 9)\t1\n",
            "  (3, 10)\t1\n",
            "  (4, 9)\t1\n",
            "  (5, 9)\t1\n",
            "  (5, 10)\t1\n",
            "  (6, 9)\t1\n",
            "  (6, 10)\t1\n",
            "  (7, 9)\t1\n",
            "  (7, 7)\t1\n",
            "  (7, 10)\t1\n",
            "  (8, 9)\t1\n",
            "  (9, 9)\t1\n",
            "  (10, 9)\t1\n",
            "  (10, 7)\t1\n",
            "  (10, 10)\t1\n",
            "  :\t:\n",
            "  (11905, 7)\t1\n",
            "  (11905, 10)\t1\n",
            "  (11905, 2)\t1\n",
            "  (11906, 9)\t1\n",
            "  (11906, 6)\t1\n",
            "  (11906, 0)\t1\n",
            "  (11907, 9)\t1\n",
            "  (11907, 6)\t1\n",
            "  (11907, 0)\t1\n",
            "  (11908, 9)\t1\n",
            "  (11908, 6)\t1\n",
            "  (11908, 0)\t1\n",
            "  (11909, 9)\t1\n",
            "  (11909, 6)\t1\n",
            "  (11909, 0)\t1\n",
            "  (11910, 9)\t1\n",
            "  (11910, 6)\t1\n",
            "  (11910, 0)\t1\n",
            "  (11911, 9)\t1\n",
            "  (11911, 6)\t1\n",
            "  (11911, 0)\t1\n",
            "  (11912, 9)\t1\n",
            "  (11912, 6)\t1\n",
            "  (11912, 0)\t1\n",
            "  (11913, 9)\t1\n",
            "\n",
            "TF-IDF:\n",
            "   (0, 10)\t0.3104299953111856\n",
            "  (0, 7)\t0.43958190745636516\n",
            "  (0, 9)\t0.3191870218289807\n",
            "  (0, 11)\t0.5515979558265544\n",
            "  (0, 3)\t0.5515979558265544\n",
            "  (1, 10)\t0.6972045559448922\n",
            "  (1, 9)\t0.7168722390842636\n",
            "  (2, 10)\t0.4961456942501392\n",
            "  (2, 7)\t0.7025631348417579\n",
            "  (2, 9)\t0.5101416388008034\n",
            "  (3, 10)\t0.6972045559448922\n",
            "  (3, 9)\t0.7168722390842636\n",
            "  (4, 9)\t1.0\n",
            "  (5, 10)\t0.6972045559448922\n",
            "  (5, 9)\t0.7168722390842636\n",
            "  (6, 10)\t0.6972045559448922\n",
            "  (6, 9)\t0.7168722390842636\n",
            "  (7, 10)\t0.4961456942501392\n",
            "  (7, 7)\t0.7025631348417579\n",
            "  (7, 9)\t0.5101416388008034\n",
            "  (8, 9)\t1.0\n",
            "  (9, 9)\t1.0\n",
            "  (10, 10)\t0.4961456942501392\n",
            "  (10, 7)\t0.7025631348417579\n",
            "  (10, 9)\t0.5101416388008034\n",
            "  :\t:\n",
            "  (11905, 10)\t0.3634222170794562\n",
            "  (11905, 7)\t0.5146211184768594\n",
            "  (11905, 9)\t0.37367411940909556\n",
            "  (11906, 0)\t0.5684336870591759\n",
            "  (11906, 6)\t0.6753915352001335\n",
            "  (11906, 9)\t0.469818494310641\n",
            "  (11907, 0)\t0.5684336870591759\n",
            "  (11907, 6)\t0.6753915352001335\n",
            "  (11907, 9)\t0.469818494310641\n",
            "  (11908, 0)\t0.5684336870591759\n",
            "  (11908, 6)\t0.6753915352001335\n",
            "  (11908, 9)\t0.469818494310641\n",
            "  (11909, 0)\t0.5684336870591759\n",
            "  (11909, 6)\t0.6753915352001335\n",
            "  (11909, 9)\t0.469818494310641\n",
            "  (11910, 0)\t0.5684336870591759\n",
            "  (11910, 6)\t0.6753915352001335\n",
            "  (11910, 9)\t0.469818494310641\n",
            "  (11911, 0)\t0.5684336870591759\n",
            "  (11911, 6)\t0.6753915352001335\n",
            "  (11911, 9)\t0.469818494310641\n",
            "  (11912, 0)\t0.5684336870591759\n",
            "  (11912, 6)\t0.6753915352001335\n",
            "  (11912, 9)\t0.469818494310641\n",
            "  (11913, 9)\t1.0\n",
            "\n",
            "Word2Vec Embeddings:\n",
            " "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t4iOZeuNBBrP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}