1. Perform tokenization (Whitespace, Punctuation-based, Treebank, Tweet, MWE) using NLTK 
   library. Use porter stemmer and snowball stemmer for stemming. Use any technique for 
   lemmatization. 
   Input / Dataset â€“use any sample sentence

2. Perform bag-of-words approach (count occurrence, normalized count occurrence), TF-IDF on 
   data.  Create embeddings using Word2Vec. 
   Dataset to be used: https://www.kaggle.com/datasets/CooperUnion/cardataset 
  
3. Perform text cleaning, perform lemmatization (any method), remove stop words (any 
   method), label encoding. Create representations using TF-IDF. Save outputs. 
   Dataset: https://github.com/PICT-NLP/BE-NLP-Elective/blob/main/3
   Preprocessing/News_dataset.pickle 

4. Create a transformer from scratch using the Pytorch library 

5. Morphology is the study of the way words are built up from smaller meaning bearing units. 
   Study and understand the concepts of morphology by the use of add delete table 
